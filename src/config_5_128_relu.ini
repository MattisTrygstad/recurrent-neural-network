[GLOBAL]
generate_data = True

[NETWORK]
epochs = 20

# 0: MSE, 1: cross-entropy
loss_function = 1

# 0: None, 1: L1, 2: L2
regularizer = 2

regularizer_rate = 0.001

learning_rate = 0.01

dataset_name = 'training'

[LAYERS]
# 0 - 5 layers with 1 - 1000 neurons
hidden_layers = [128, 128, 128, 128]

# 0: sigmoid, 1: tanh, 2: relu, 3: linear
activation_functions = [2, 2, 2, 2]

# If no range is specified, glorot initializer will be used
weight_ranges = [(-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1), (-0.1, 0.1)]

# If no learning rate is specified, the global learning rate will be used
custom_learing_rates = [None, None, None, None]

# 0: sigmoid, 1: tanh, 2: relu, 3: linear, 4: softmax
output_activation_function = 4

[DATA_GENERATION]
; dataset_size = 10000
; canvas_size = 50
; noise_ratio = 0.1
; pos_deviaiton = 0.2
; line_width_deviaiton = 0.4
; width_range = (10, 40)
; height_range= (10, 40)
; split_ratios= (0.7, 0.2, 0.1)

dataset_size = 5000
canvas_size = 50
noise_ratio = 0.05
pos_deviaiton = 0.15
line_width_deviaiton = 0.3
width_range = (20, 30)
height_range= (20, 30)
split_ratios= (0.7, 0.2, 0.1)